{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates \n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Flatten,LeakyReLU, Dense, Dropout, GlobalMaxPooling2D, Activation, Input,LSTM, Reshape, Conv2D, MaxPooling2D,ConvLSTM2D\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "from time import time\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, train, labels, positives, negatives, model, batch_size) :\n",
    "        self.train = train\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.positives = positives\n",
    "        self.negatives = negatives\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.train) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx) :\n",
    "\n",
    "        sequence = random.choices(self.positives, k = int(self.batch_size/2)) + random.choices(self.negatives, k = int(self.batch_size/2))\n",
    "\n",
    "        batch_x = np.asarray([self.train[i-500:i] for i in sequence])\n",
    "        temp = self.labels[sequence].astype(int)\n",
    "        batch_y = np.zeros((temp.size, temp.max()+1))\n",
    "        batch_y[np.arange(temp.size),temp] = 1\n",
    "        \n",
    "        if self.model == \"LSTM\":\n",
    "            return np.reshape(batch_x[:,400:500,:,:],(batch_size, 100, 42,7,1)), batch_y,[None]\n",
    "        else:\n",
    "            return batch_x, batch_y, [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_file_time(idx):\n",
    "    if idx < 2:\n",
    "        month = 5\n",
    "        day = 31\n",
    "        hour = 23\n",
    "    else:\n",
    "        month = 6\n",
    "        if idx < 26:\n",
    "            day = 1\n",
    "        else:\n",
    "            day = 2\n",
    "        hour = (idx - 2) % 24\n",
    "        \n",
    "    return str(month), str(day), str(hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(idx):\n",
    "    \n",
    "    month, day, hour = calculate_file_time(idx)\n",
    "    v_month, v_day, v_hour = calculate_file_time(idx+1)\n",
    "    \n",
    "    train_input = np.abs(np.load(\"./01_Data/\" + str(idx) + \" Input hour 2020_\"+month+\"_\"+day+\"_\"+hour+\"_20.npy\").transpose(0, 2, 1))\n",
    "    train_input[train_input > 1] = 1\n",
    "    train_input[np.isnan(train_input)] = 0\n",
    "    train_labels = np.load(\"./01_Data/\" + str(idx) + \" Labels.npy\")\n",
    "    \n",
    "    val_input = np.abs(np.load(\"./01_Data/\" + str(idx + 1) + \" Input hour 2020_\"+v_month+\"_\"+v_day+\"_\"+v_hour+\"_20.npy\").transpose(0, 2, 1))\n",
    "    val_input[val_input > 1] = 1\n",
    "    val_input[np.isnan(val_input)] = 0\n",
    "    val_labels = np.load(\"./01_Data/\" + str(idx + 1) + \" Labels.npy\")\n",
    "    \n",
    "    return train_input,train_labels,val_input,val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_callback(idx, train_input, p, n, val_in, val_lab, positives, negatives, folder):\n",
    "    if idx == 10:\n",
    "        callbacks = [ModelCheckpoint(filepath='00_Models\\\\'+folder+'\\\\'+ str(idx) +'.h5', monitor='val_loss', save_best_only=True),\n",
    "             TensorBoard(log_dir='.\\\\02_TB_logs\\\\'+folder+'\\\\' + str(idx) + \"_\" + '{}'.format(time()),\n",
    "                         histogram_freq = 0,\n",
    "                         write_graph = True),\n",
    "#             EarlyStopping(monitor='val_loss', min_delta = 0.0001, patience = 3),\n",
    "            EarlyStopping(monitor='loss', min_delta = 0.00002, patience = 1)]\n",
    "    else:\n",
    "        callbacks = [ModelCheckpoint(filepath='00_Models\\\\'+folder+'\\\\'+ str(idx) +'.h5', monitor='val_loss', save_best_only=True),\n",
    "             TensorBoard(log_dir='.\\\\02_TB_logs\\\\'+folder+'\\\\' + str(idx) + \"_\" + '{}'.format(time()),\n",
    "                         histogram_freq = 0,\n",
    "                         write_graph = False,\n",
    "                         profile_batch=0),\n",
    "#              EarlyStopping(monitor='val_loss', min_delta = 0.0001, patience = 3),\n",
    "             EarlyStopping(monitor='loss', min_delta = 0.00002, patience = 1)]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- DeepLOB\n",
    "https://github.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books/blob/master/jupyter/run_train_represent.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deeplob(T, NF, CH, number_of_lstm):\n",
    "    input_lmd = Input(shape=(T, NF, CH))\n",
    "    \n",
    "    # build the convolutional block\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(input_lmd)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 10))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    \n",
    "    # build the inception module\n",
    "    convsecond_1 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "    convsecond_1 = Conv2D(64, (3, 1), padding='same')(convsecond_1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "\n",
    "    convsecond_2 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "    convsecond_2 = Conv2D(64, (5, 1), padding='same')(convsecond_2)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "\n",
    "    convsecond_3 = MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n",
    "    convsecond_3 = Conv2D(64, (1, 1), padding='same')(convsecond_3)\n",
    "    convsecond_3 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_3)\n",
    "    \n",
    "    convsecond_output = keras.layers.concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n",
    "\n",
    "    # use the MC dropout here\n",
    "    conv_reshape = Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(convsecond_output)\n",
    "\n",
    "    # build the last LSTM layer\n",
    "    conv_lstm = CuDNNLSTM(number_of_lstm)(conv_reshape)\n",
    "\n",
    "    # build the output layer\n",
    "    out = Dense(2, activation=\"softmax\")(conv_lstm)\n",
    "    model = Model(inputs=input_lmd, outputs=out)\n",
    "    opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy',\n",
    "                                                                           tf.keras.metrics.Precision(name = \"Precision\", class_id=1),\n",
    "                                                                           tf.keras.metrics.Recall(name = \"Recall\", class_id=1)])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 500, 42, 7)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 500, 21, 32)  480         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 500, 21, 32)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 500, 21, 32)  4128        leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 500, 21, 32)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 500, 21, 32)  4128        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 500, 21, 32)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 500, 10, 32)  2080        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 500, 10, 32)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 500, 10, 32)  4128        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 500, 10, 32)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 500, 10, 32)  4128        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 500, 10, 32)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 500, 1, 32)   10272       leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 500, 1, 32)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 500, 1, 32)   4128        leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 500, 1, 32)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 500, 1, 32)   4128        leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 500, 1, 32)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 500, 1, 64)   2112        leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 500, 1, 64)   2112        leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 500, 1, 64)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 500, 1, 64)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 500, 1, 32)   0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 500, 1, 64)   12352       leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 500, 1, 64)   20544       leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 500, 1, 64)   2112        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 500, 1, 64)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 500, 1, 64)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 500, 1, 64)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 500, 1, 192)  0           leaky_re_lu_16[0][0]             \n",
      "                                                                 leaky_re_lu_18[0][0]             \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 500, 192)     0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)          (None, 64)           66048       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            130         cu_dnnlstm[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 143,010\n",
      "Trainable params: 143,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =  create_deeplob(500, 42, 7, 64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,44):\n",
    "    train_input_p,train_labels_p, val_input, val_labels = read_data(i)\n",
    "    model =  create_deeplob(500, 42, 7, 64)\n",
    "    if i == 1:\n",
    "        train_input = train_input_p\n",
    "        train_labels = train_labels_p\n",
    "    else:\n",
    "        train_input = np.append(train_input,train_input_p, axis = 0)\n",
    "        train_labels = np.append(train_labels,train_labels_p)\n",
    "\n",
    "    positives = np.where(train_labels[500::] == 1)[0] + 500\n",
    "    negatives = np.where(train_labels[500::] == 0)[0] + 500\n",
    "    positives_val = np.where(val_labels[500::] == 1)[0] + 500\n",
    "    negatives_val = np.where(val_labels[500::] == 0)[0] + 500 \n",
    "    \n",
    "    j = 1\n",
    "    while len(positives_val) < batch_size // 2:\n",
    "        if i+j>=44:\n",
    "            print(\"NOT ENOUGH DATA TO FINISH\")\n",
    "        train_input_p,train_labels_p, val_input_p, val_labels_p = read_data(i + j)\n",
    "        val_input = np.append(val_input,val_input_p, axis = 0)\n",
    "        val_labels = np.append(val_labels,val_labels_p)  \n",
    "        \n",
    "        positives_val = np.where(val_labels[500::] == 1)[0] + 500\n",
    "        negatives_val = np.where(val_labels[500::] == 0)[0] + 500   \n",
    "        \n",
    "        j += 1\n",
    "\n",
    "   \n",
    "    \n",
    "    callb = calculate_callback(i,train_input, positives, negatives, val_input, val_labels, positives_val, negatives_val, \"DLOB2\")\n",
    "\n",
    "\n",
    "    tr_batch_generator  = My_Custom_Generator(train_input, train_labels, positives, negatives, \"DLOB2\", batch_size)\n",
    "    val_batch_generator = My_Custom_Generator(val_input, val_labels, positives_val, negatives_val, \"DLOB2\", batch_size)    \n",
    "    \n",
    "    t_steps = min(len(train_input)//batch_size, len(positives)//(batch_size//2),2000)\n",
    "    t_steps_val = min(max(len(val_input)//batch_size,750), max(len(positives_val)//(batch_size//2),750),750)\n",
    "    \n",
    "    print(\"-----------------------\")\n",
    "    print(\"MODEL \" + str(i))\n",
    "    print(\"-----------------------\")\n",
    "    model.fit(tr_batch_generator,\n",
    "                       steps_per_epoch = t_steps,\n",
    "                       epochs = 200,\n",
    "                       verbose = 1,\n",
    "                       validation_data = val_batch_generator,\n",
    "                       validation_steps = t_steps_val, \n",
    "                       callbacks = callb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.- VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG(X,Y,CH):\n",
    "    vg = VGG16(include_top=False, weights='imagenet')\n",
    "    vg.layers.pop()\n",
    "    vg.trainable = False\n",
    "    dense_input = tf.keras.layers.Input(shape=(X, Y, CH))\n",
    "    dense_filter = tf.keras.layers.Conv2D(5, 3, padding='same')(dense_input)\n",
    "    dense_filter = keras.layers.LeakyReLU(alpha=0.01)(dense_filter)\n",
    "    \n",
    "    dense_filter = tf.keras.layers.Conv2D(3, 3, padding='same')(dense_filter)\n",
    "    dense_filter = keras.layers.LeakyReLU(alpha=0.01)(dense_filter)    \n",
    "\n",
    "    baseline = vg(dense_filter)\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(baseline)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=dense_input, outputs=predictions)\n",
    "\n",
    "    opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy',\n",
    "                                                                           tf.keras.metrics.Precision(name = \"Precision\", class_id=1),\n",
    "                                                                           tf.keras.metrics.Recall(name = \"Recall\", class_id=1)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 500, 42, 7)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 500, 42, 5)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 500, 42, 5)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 500, 42, 3)        138       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 500, 42, 3)        0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 15,766,284\n",
      "Trainable params: 1,051,596\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG(500, 42, 7)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "for k in range(1,5):\n",
    "    for i in range(2,10*k):\n",
    "        train_input_p,train_labels_p, val_input, val_labels = read_data(i)\n",
    "        if i == 2:\n",
    "            train_input = train_input_p\n",
    "            train_labels = train_labels_p\n",
    "        else:\n",
    "            train_input = np.append(train_input,train_input_p, axis = 0)\n",
    "            train_labels = np.append(train_labels,train_labels_p)\n",
    "            \n",
    "    positives = np.where(train_labels[500::] == 1)[0] + 500\n",
    "    negatives = np.where(train_labels[500::] == 0)[0] + 500\n",
    "    positives_val = np.where(val_labels[500::] == 1)[0] + 500\n",
    "    negatives_val = np.where(val_labels[500::] == 0)[0] + 500   \n",
    "    \n",
    "    j = 1\n",
    "    while len(positives_val) < batch_size // 2:\n",
    "        if i+j>=44:\n",
    "            print(\"NOT ENOUGH DATA TO FINISH\")\n",
    "        train_input_p,train_labels_p, val_input_p, val_labels_p = read_data(i + j)\n",
    "        val_input = np.append(val_input,val_input_p, axis = 0)\n",
    "        val_labels = np.append(val_labels,val_labels_p)  \n",
    "        \n",
    "        positives_val = np.where(val_labels[500::] == 1)[0] + 500\n",
    "        negatives_val = np.where(val_labels[500::] == 0)[0] + 500   \n",
    "        \n",
    "        j += 1    \n",
    "        \n",
    "    model = VGG(500, 42, 7)\n",
    "\n",
    "    callb = calculate_callback(10*k,train_input, positives, negatives, val_input, val_labels, positives_val, negatives_val, \"VGG4\")\n",
    "    \n",
    "    tr_batch_generator  = My_Custom_Generator(train_input, train_labels, positives, negatives, \"VGG4\", batch_size)\n",
    "    val_batch_generator = My_Custom_Generator(val_input, val_labels, positives_val, negatives_val, \"VGG4\", batch_size)    \n",
    "    \n",
    "    t_steps = min(len(train_input)//batch_size, len(positives)//(batch_size//2),1000)\n",
    "    t_steps_val = min(len(val_input)//batch_size, len(positives_val)//(batch_size//2),500)    \n",
    "    print(\"----------------------\")\n",
    "    print(\"MODEL \" + str(10*k))\n",
    "    print(\"----------------------\")\n",
    "    model.fit(tr_batch_generator,\n",
    "                       steps_per_epoch = t_steps,\n",
    "                       epochs = 200,\n",
    "                       verbose = 1,\n",
    "                       validation_data = val_batch_generator,\n",
    "                       validation_steps = t_steps_val,\n",
    "                       callbacks = callb)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
